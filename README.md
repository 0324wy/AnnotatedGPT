# AnnotatedGPT

This a simple version of GPT model with 300 lines of code.

The project is adapted from [The Annotated Transformer](https://github.com/harvardnlp/annotated-transformer).

The transformer is encoder-decoder architecture, but the GPT is decoder-only architecture. This is the main difference between these two projects. Other than that, most of the code is the same as that project.

## The Decoder-Only Architecture

![](https://p.ipic.vip/jud7nh.png)

## The Encoder-Decoder Architecture

![](https://p.ipic.vip/va821s.png)
